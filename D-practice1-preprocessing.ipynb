{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VJnmKUUMEvf"
      },
      "source": [
        "\n",
        "## Practice 1: Pre-processing images (framework step 2)\n",
        "\n",
        "This is the second notebook of the online course on using machine learning tools for image processing practice.\n",
        "\n",
        "To work on the exercices you can open this notebook by clicking the badge below. To work on the exercices you can open this notebook by clicking the badge below. This will open a new notebook for your personal use and you can modify it and don't forget to save it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIOgqTPLY1Rd"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/fishsizeproject/Course-MLforImageProcessing/blob/dev/4-practice-1.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4XGxDrCkeip"
      },
      "source": [
        "## Setup \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVC3FGNgjcvK"
      },
      "source": [
        "Images collected by citizens or extracted from internet may contain sensitive data, such as peopleâ€™s faces. Depending on the nature of subsequent work (e.g. crowdsourced annotation of images), it may be preferrable to remove such data. In this practice we will use the Python library CVlib and the pre-trained model caffemodel to detect human faces.\n",
        "\n",
        "First we need to install the required libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7RJpY-6jMtC"
      },
      "outputs": [],
      "source": [
        "!pip install cvlib\n",
        "\n",
        "# import libraries\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import cvlib as cv\n",
        "\n",
        "\n",
        "# For drawing onto the image.\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageColor\n",
        "from PIL import ImageDraw\n",
        "from PIL import ImageFont\n",
        "from PIL import ImageOps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C7duuNqjR7D"
      },
      "source": [
        "# Read an image and visualize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn2c8NGWMYFp"
      },
      "source": [
        "As in the previous notebook, we will read and visualize an image first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1PP4jImICA4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "git_folder = \"fishsizeproject/Course-MLforImageProcessing\"\n",
        "if os.path.exists(git_folder) == False:\n",
        "   !git clone --branch dev https://github.com/fishsizeproject/Course-MLforImageProcessing.git  #### CHANGE BRANCH TO MAIN !\n",
        "\n",
        "path_to_images = git_folder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCB8if_MQ3bZ"
      },
      "outputs": [],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nfa2JczUICHd"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "cv2.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwO_3rkyIMRH"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread('./Course-MLforImageProcessing/images/IMG_0134.JPG')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGafCgP4IMTl"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def visualize_RGB(image):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "\n",
        "visualize_RGB(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OqcvSm3Mjyp"
      },
      "source": [
        "## Detect faces, draw a bounding box and fill with colour"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64DnBCLYnIZo"
      },
      "source": [
        "In this practice we will use the function `detect_face()` of the Python library CVlib and the pre-trained model caffemodel to detect human faces. \n",
        "\n",
        "After face detection, a rectangle is drawn around the face using the `cv2.rectangle()` function and an overlay is applied to the image content inside the rectangle to remove sensitive data before further analyses.\n",
        "\n",
        "The Syntax of this function is `cv2.rectangle(image, start_point, end_point, color, thickness)` and by setting thickness of -1 px we will fill the rectangle shape by the specified color."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z1dhY9dIR3i"
      },
      "outputs": [],
      "source": [
        "# create a copy of the original image to draw the box in\n",
        "output = img.copy()\n",
        " \n",
        "\t# draw a rectangle surrounding faces in the image\n",
        "faces, confidences = cv.detect_face(output)\n",
        "  # loop through detected faces and add bounding box\n",
        "for face in faces:\n",
        "    (startX,startY) = face[0],face[1]\n",
        "    (endX,endY) = face[2],face[3]\n",
        "  # draw rectangle over face\n",
        "cv2.rectangle(output, (startX,startY), (endX,endY), (0, 0, 0), -1)\n",
        " \n",
        " # display output\n",
        "visualize_RGB(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOLjbecSU4rq"
      },
      "source": [
        "# Exercise - Draw the bounding box only (do not overlay)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zPqiDyVWEIP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
